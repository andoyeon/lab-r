classifier2 <- ksvm(letter ~ .,
data = letters_train,
kernel = "rbfdot")
predict2 <- predict(classifier2, letters_test)
head(predict2, n = 10)
head(predict2, n = 10)
head(letters_test$letter, n = 10)
correct2 <- ifelse(predict2 == letters_test$letter, 1, 0)
correct2_count <- sum(correct2)
correct2_count
correct2_ratio <- correct2_count / 4000
correct_ratio
correct2_ratio <- correct2_count / 4000
correct_ratio
correct2_ratio
table(predict2, letters_test$letter)
rm(list = ls())
# 1. 데이터 준비
letters <- read.csv(file = "mlwr/letterdata.csv")
# 2. 데이터 확인
str(letters)
head(letter)
head(letters)
# 학습/테스트 데이터 세트 (80%:20%)
letter_train <- letters[1:1600, ]
# 학습/테스트 데이터 세트 (80%:20%)
letter_train <- letters[1:16000, ]
letter_test <- letters[16001:20000]
letter_test <- letters[16001:20000, ]
table(letter_train)
table(letter_train$letter)
table(letter_test$letter)
# 3. SVM 알고리즘 모델 생성: classifier
classifier <- ksvm(letter ~ .,
data = letter_train,
kernel = "rbfdot")
head(classifier)
# 4. 모델 평가
letters_predict <- predict(classifier, letters_test)
# 4. 모델 평가
letters_predict <- predict(classifier, letter_test)
head(letters_predict)
letter_test[ ,1]
head(letter_test$letter, n = 10)
head(letters_predict)
head(letter_test$letter, n = 10)
head(letters_predict, n = 10)
table(letter_test, letters_predict)
table(letter_test$letter, letters_predict)
correct <- ifelse(letters_predict === letter_test$letter, 1, 0)
correct <- ifelse(letters_predict == letter_test$letter, 1, 0)
table(correct)
correct
correct_sum <- sum(correct)
correct_sum
correct_ratio <- correct_sum / 4000
correct_ratio
rm(list = ls())
# 1. 데이터 준비
groceries <- read.csv(file = "mlwr/groceries.csv)
# 1. 데이터 준비
groceries <- read.csv(file = "mlwr/groceries.csv")
# 1. 데이터 준비
groceries <- read.csv(file = "mlwr/groceries.csv")
str(groceries)
head(groceries)
# 1. 데이터 준비
groceries <- read.csv(file = "mlwr/groceries.csv", header = F)
str(groceries)
head(groceries)
tail(groceries)
head(groceries, n = 10)
# 1. 데이터 준비
groceries <- read.csv(file = "mlwr/groceries.csv", header = F)
str(groceries)
head(groceries, n = 10)
# arules 패키지: association rules(연관 규칙) 패키지
install.packages("arules")
library(arules)
search()
# 장바구니 영수증 데이터(csv)를 희소 행렬로 만듦
groceries <- read.transactions(file = "mlwr/groceries.csv",
header = F,
sep = ",")
# read.transaction 함수에서
# header 파라미터의 기본값은 FALSE
# sep 파라미터의 기본값은 ""이기 때문에, 반드시 ","를 전달해야 함.
summary(groceries)
inspect(groceries)
inspect(groceries[1:5])
inspect(groceries[9831:9835])
inspect(groceries[ ,1:5])
# 영수증에 등장하는 아이템들의 빈도(frequency)
itemFrequency(groceries[, 1:5])
itemFrequency(groceries[, 165:169])
# 거래 아이템들의 빈도 분포
itemFrequencyPlot(groceries, support = 0.1)
# support: 영수증에 아이템이 나타나는 횟수
# 최소 10% 이상 나타나는 아이템들만 그래프에 표시
itemFrequencyPlot(groceries, topN = 20)
# 희소 행렬(sparse matrix)를 그래프로 표시
image(groceries[1:100, ])
# 3. 모델 학습 - 자율(비지도) 학습인 한 종류 a priori 알고리즘
grocery_rules <- apriori(data = groceries)
summary(grocery_rules)
300 / 9835
grocery_rules2 <- apriori(data = groceries,
parameter = list(support = 0.03,
confidence = 0.25,
minlen = 2))
summary(grocery_rules2)
inspect(grocery_rules2)
inspect(grocery_rules2)
60 / 9835
grocery_rules3 <- apriori(data = groceries,
parameter = list(support = 0.006,
confidence = 0.25,
minlen = 2))
summary(grocery_rules3)
inspect(grocery_rules3[1:5])
inspect(grocery_rules3[1:10])
inspect(grocery_rules3[1:10])
inspect(grocery_rules3[1:10])
inspect(grocery_rules3[400:410])
inspect(grocery_rules3[400:410])
summary(grocery_rules)
# 1. 데이터 준비
groceries <- read.csv(file = "mlwr/groceries.csv", header = F)
# 장바구니 영수증 데이터(csv)를 희소 행렬로 만듦
groceries <- read.transactions(file = "mlwr/groceries.csv",
header = F,
sep = ",")
# read.transaction 함수에서
# header 파라미터의 기본값은 FALSE
# sep 파라미터의 기본값은 ""이기 때문에, 반드시 ","를 전달해야 함.
summary(groceries)
# 각 영수증(transaction/example)의 아이템들을 확인
inspect(groceries)
inspect(groceries[1:5])
inspect(groceries[9831:9835])
# 영수증에 등장하는 아이템들의 빈도(frequency)
itemFrequency(groceries[, 1:5])
itemFrequency(groceries[, 165:169])
# 거래 아이템들의 빈도 분포
itemFrequencyPlot(groceries, support = 0.1)
# support: 영수증에 아이템이 나타나는 횟수
# 최소 10% 이상 나타나는 아이템들만 그래프에 표시
itemFrequencyPlot(groceries, topN = 20)
# 희소 행렬(sparse matrix)를 그래프로 표시
image(groceries[1:100, ])
# 3. 모델 학습 - 자율(비지도) 학습인 한 종류 a priori 알고리즘
grocery_rules <- apriori(data = groceries)
summary(grocery_rules)
grocery_rules2 <- apriori(data = groceries,
parameter = list(support = 0.03,
confidence = 0.25,
minlen = 2))
summary(grocery_rules2)
grocery_rules2 <- apriori(data = groceries,
parameter = list(support = 0.03,
confidence = 0.25,
minlen = 2))
summary(grocery_rules2)
inspect(grocery_rules2)
grocery_rules3 <- apriori(data = groceries,
parameter = list(support = 0.006,
confidence = 0.25,
minlen = 2))
summary(grocery_rules3)
inspect(grocery_rules3[400:410])
inspect(grocery_rules3[400:410])
inspect(grocery_rules3[1:10])
inspect(grocery_rules3[201:210])
inspect(grocery_rules3[201:210])
inspect(sort(grocery_rules3))
inspect(sort(grocery_rules3, by = "lift")[1:10])
inspect(sort(grocery_rules3, by = "lift")[1:10])
rm(list = ls())
teens <- read.csv(file = "mlwr/snsdata.csv")
# 데이터 확인
str(teens)
head(teens)
# 몇가지 변수(특징)에서 결측치(NA)가 보임
summary(teens)
# gender 변수의 NA 갯수
table(is.na(teens$gender))
table(teens$gender)
table(teens$gender, useNA = "ifany")
# female 변수를 데이터 프레임에 추가
# 성별이 "F"이고 NA아니면 1, 그렇지 않으면 0을 입력
teens$female <- ifelse(teens$gender == "F" & !is.na(teens$gender),
1, 0)
table(teens$female)
table(teens$female, useNA = "ifany")
# nogender 변수를 데이터 프레임에 추가
# gender 변수가 NA이면 1, 그렇지 않으면 0을 입력
teens$nogender <- ifelse(is.na(teens$geder), 1, 0)
# nogender 변수를 데이터 프레임에 추가
# gender 변수가 NA이면 1, 그렇지 않으면 0을 입력
teens$nogender <- ifelse(is.na(teens$gender), 1, 0)
table(teens$nogender, useNA = "ifany")
# age 변수 확인
summary(teens$age)
summary(teens$age)
# age의 정상 범위는 13 ~ 19라고 가정 -> 이외의 값들은 NA
teens$age <- ifelse(teens$age >= 13 & teens$age <= 19,
teens$age, NA)
summary(teens$age)
# age의 NA들을 gradyear별 age의 평균값으로 대체
# dplyr 패키지 이용
library(dplyr)
teens %>%
group_by(gradyear) %>%
filter(!is.na(age)) %>%
summarise(mean(age))
teens %>%
group_by(gradyear) %>%
summarise(mean(age, na.rm = T))
teens %>%
group_by(gradyear) %>%
summarise(mean(age, na.rm = T))
# 그룹별 평균(또는 임의 함수)를 적용해서 벡터를 리턴하는 함수
# stats::ave(평균을 계산할 벡터, 그룹핑 변수, FUN = mean)
df <- data.frame(class = c(1, 1, 1, 2, 2),
score = c(10, 9, NA, 9, 8))
# 그룹별 평균(또는 임의 함수)를 적용해서 벡터를 리턴하는 함수
# stats::ave(평균을 계산할 벡터, 그룹핑 변수, FUN = mean)
df <- data.frame(class = c(1, 1, 1, 2, 2),
score = c(10, 9, 8, 9, 8))
df
ave(df$score, df$class, FUN = mean)
# 그룹별 평균(또는 임의 함수)를 적용해서 벡터를 리턴하는 함수
# stats::ave(평균을 계산할 벡터, 그룹핑 변수, FUN = mean)
df <- data.frame(class = c(1, 1, 1, 2, 2),
score = c(10, 9, NA, 9, 8))
df
ave(df$score, df$class, FUN = mean)
my_mean <- function(x) {
mean(x, na.rm = T)
}
ave(df$score, df$class, FUN = my_mean)
ave_age <- ave(teens$age, teens$gradyear, FUN = my_mean)
head(ave_age)
tail(ave_age)
teens$age <- ifelse(is.na(teens$age), ave_age, teens$age)
summary(teens$age)
# k-평균 군집화 알고리즘의 모델을 생성
str(teens)
# 개인 식별 정보(gradyear, gender, age, friends)를 제외하고,
# 오로지 관심사들로만 clustering을 시도
interests <- teens[5:40]
stR(interests)
str(interests)
set.seed(2345)
teen_clusters <- kmeans(interests, 5)
str(teen_clusters)
str(teen_clusters$cluster)
table(teen_clusters$cluster)
teens[c("cluster", "gender", "age", "friends")]
teens[1:10, c("cluster", "gender", "age", "friends")]
teens[1:10, c("cluster", "gender", "age", "friends")]
# 데이터 확인
str(teens)
teens[1:10, c("cluster", "gender", "age", "friends")]
# 모델이 분류한 클러스트가 어떤 특징들을 갖고 있을까?
teens$cluster <- teen_clusters$cluster
teens[1:10, c("cluster", "gender", "age", "friends")]
teens[1:10, c("cluster", "gender", "age", "friends")]
teen_clusters$centers
rm(list = ls())
# 데이터 준비
teens <- read.csv(file = "mlwr/snsdata.csv")
# 데이터 확인
str(teens)
table(teens$gender)
table(teens$gender, useNA = "ifany")
summary(teens)
# 결측치 처리 - 새로운 변수 생성
# 성별
teens$female <- ifelse(teens$gender == "F"$ !is.na(teens$gender),
1, 0)
# 결측치 처리 - 새로운 변수 생성
# 성별
teens$female <- ifelse(teens$gender == "F" $ !is.na(teens$gender),
1, 0)
# 결측치 처리 - 새로운 변수 생성
# 성별
teens$female <- ifelse(teens$gender == "F" &!is.na(teens$gender),
1, 0)
table(teens$gender, useNA = "ifany")
table(teens$female, useNA = "ifany")
# NA값 변수 생성
teens$nogender <- iselse(is.na(teens$gender),
1, 0)
# NA값 변수 생성
teens$nogender <- ifelse(is.na(teens$gender),
1, 0)
table(teens$nogender)
sumary(teens)
summary(teens)
# age 변수 확인
summary(teens$age)
# age 정상 범위: 13 ~ 19, 이외 값은 모두 NA 처리
teens$age <- ifelse(teens$age >= 13 & teens$age <=19,
teens$age, NA)
summary(teens$age)
# age의 NA들을 gradyear별 age의 평균값으로 대체
teens %>%
group_by(gradyear) %>%
filter(is.na(age)) %>%
summarise(mean(age))
# age의 NA들을 gradyear별 age의 평균값으로 대체
teens %>%
group_by(gradyear) %>%
filter(!is.na(age)) %>%
summarise(mean(age))
table(teens$female, useNA = "ifany")
table(teens$nogender, useNA = "ifany")
teens %>%
group_by(gradyear) %>%
summarise(mean(age), na.rm = T)
teens %>%
group_by(gradyear) %>%
summarise(mean(age, na.rm = T))
mean(x, na.rm = T)
# 그룹별 평균을 적용해서 벡터를 리턴하는 함수: ave
my_mean <- function(x) {
mean(x, na.rm = T)
}
ave_age <- ave(teens$age, teens$gradyear, FUN = my_mean)
table(ave_age)
summary(ave_age)
str(teens)
# 클러스터링 모델 생성(개인 식별 정보 제외)
interests <- teens[5:40]
set.seed(123)
teen_clusters <- kmeans(interests, 5)
str(teen_clusters)
normalize <- function(x) {
ruturn((x - min(x)) / (max(x) - min(x)))
}
interests_norm <- as.data.frame(lapply(interests, normalize))
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
interests_norm <- as.data.frame(lapply(interests, normalize))
summary(interests_norm)
teen_clusters <- kmeans(interests_norm, 5)
str(teen_clusters)
# 클러스트 특징
teens$cluster <- teen_clusters$cluster
teens[1:10, c("cluster", "gender", "age", "friends")]
teen_clusters$centers
teen_clusters <- kmeans(interests_norm, 5)
# 클러스트 특징
teens$cluster <- teen_clusters$cluster
teens[1:10, c("cluster", "gender", "age", "friends")]
teen_clusters$centers
teen_clusters$size
summary(teen_clusters)
str(teen_clusters)
str(teen_clusters)
summary(interests_norm)
teen_clusters$centers
rm(list = ls())
# 데이터 준비
teens <- read.csv(file = "mlwr/snsdata.csv")
table(teens$gender, useNA = "ifany")
# female 변수를 데이터 프레임에 추가
# 성별이 "F"이고 NA아니면 1, 그렇지 않으면 0을 입력
teens$female <- ifelse(teens$gender == "F" & !is.na(teens$gender),
1, 0)
# nogender 변수를 데이터 프레임에 추가
# gender 변수가 NA이면 1, 그렇지 않으면 0을 입력
teens$nogender <- ifelse(is.na(teens$gender), 1, 0)
# age의 정상 범위는 13 ~ 19라고 가정 -> 이외의 값들은 NA
teens$age <- ifelse(teens$age >= 13 & teens$age <= 19,
teens$age, NA)
# age의 NA들을 gradyear별 age의 평균값으로 대체
# dplyr 패키지 이용
library(dplyr)
teens %>%
group_by(gradyear) %>%
filter(!is.na(age)) %>%
summarise(mean(age))
# 그룹별 평균(또는 임의 함수)를 적용해서 벡터를 리턴하는 함수
# stats::ave(평균을 계산할 벡터, 그룹핑 변수, FUN = mean)
df <- data.frame(class = c(1, 1, 1, 2, 2),
score = c(10, 9, NA, 9, 8))
my_mean <- function(x) {
mean(x, na.rm = T)
}
ave(df$score, df$class, FUN = my_mean)
ave_age <- ave(teens$age, teens$gradyear, FUN = my_mean)
teens$age <- ifelse(is.na(teens$age), ave_age, teens$age)
# 개인 식별 정보(gradyear, gender, age, friends)를 제외하고,
# 오로지 관심사들로만 clustering을 시도
interests <- teens[5:40]
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
interests_norm <- as.data.frame(lapply(interests, normalize))
set.seed(2345)
teen_clusters <- kmeans(interests_norm, 5)
# 모델이 분류한 클러스트가 어떤 특징들을 갖고 있을까?
teens$cluster <- teen_clusters$cluster
teens[1:10, c("cluster", "gender", "age", "friends")]
teen_clusters$centers
rm (list = ls())
# model <- naiveBayse(훈련 데이터, ...)
# predict <- predict(model, 테스트 데이터, type = "...")
sms_results <- read.csv(file = "mlwr/sms_results.csv")
heaD(sms_results)
head(sms_results)
library(dplyr)
sms_results %>%
filter(prob_spam > 0.4 & prob_spam < 0.6) %>%
head(n = 10)
# 실제 값과 예측 값이 다른 경우
sms_results %>%
filter(actual_type != predict_type) %>%
head(n = 10)
# 실제 값과 예측 값이 다른 경우
sms_results %>%
filter(actual_type != predict_type) %>%
tail(n = 10)
# 혼동 행렬(confusion matrix)
table(sms_results$actual_type, sms_results$predict_type)
library(gmodels)
CrossTable(sms_results$actual_type, sms_results$predict_type)
# kappa 통계량 계산
# Pr(a): 실제 일치(actual aggrement) 비율
# TN + TP
pr_a <-
# kappa 통계량 계산
# Pr(a): 실제 일치(actual aggrement) 비율
# TN + TP
pr_a <- 0.865 + 0.109
pr_a
# pre(e): 예상 일치(expected agreement) 비율
# 독립 사건이라는 가정 아래에서
# P(실제 스팸) x p(예측 스팸) + p(실제 햄) x P(예측 햄)
pr_e = (0.022 + 0.109) * (0.003 + 0.109) + (0.865 + 0.003) x (0.865 + 0.022)
# pre(e): 예상 일치(expected agreement) 비율
# 독립 사건이라는 가정 아래에서
# P(실제 스팸) x p(예측 스팸) + p(실제 햄) x P(예측 햄)
pr_e = (0.022 + 0.109) * (0.003 + 0.109) + (0.865 + 0.003) * (0.865 + 0.022)
kappa <- (pr_a - pr_e) / (1 - pr_e)
# pre(e): 예상 일치(expected agreement) 비율
# 독립 사건이라는 가정 아래에서
# P(실제 스팸) x p(예측 스팸) + p(실제 햄) x P(예측 햄)
pr_e <- 0.132 * 0.112 + 0.868 * 0.888
kappa <- (pr_a - pr_e) / (1 - pr_e)
install.packages("caret")
library(caret)
confusionMatrix(sms_results$actual_type, sms_results$predict_type,
positive = "spam")
CrossTable(sms_results$actual_type, sms_results$predict_type)
confusionMatrix(sms_results$predict_type, sms_results$actual_type,
positive = "spam")
sensitivity(data = sms_results$predict_type,
reference = sms_results$actual_type,
positive = "spam")
# 특이도
specificity(data = sms_results$predict_type,
reference = sms_results$actual_type,
negative = "ham")
# 정밀도
precision(data = sms_results$predict_type,
reference = sms_results$actual_type,
relevant = "spam")
F_meas(data = sms_results$predict_type,
reference = sms_results$actual_type,
relevant = "spam")
f <- (2 * 0.974359 * 0.8306011) / (0.974359 + 0.8306011)
f
# ROC(Receiver Operation Characteristic) 곡선
install.packages("pROC")
library(pROC)
sms_roc <- roc(response = sms_results$actual_type,
predictor = sms_results$prob_spam)
plot(sms_roc)
plot(sms_roc, col = "darkblue")
plot(sms_roc, col = "darkblue", lwd = 2)
plot(sms_roc, col = "darkblue", lwd = 10)
plot(sms_roc, col = "darkblue", lwd = 5)
plot(sms_roc, col = "darkblue", lwd = 3)
plot(sms_roc, col = "darkblue", lwd = 2)
plot(sms_roc, col = "darkblue", lwd = 3)
sns_knn <- read.csv(file = "mlwr/sms_results_knn.csv")
head(sns_knn)
sms_knn <- read.csv(file = "mlwr/sms_results_knn.csv")
knn_roc <- roc(response = sms_results$actual_type,
predictor = sms_knn$p_spam)
sms_knn_roc <- roc(response = sms_results$actual_type,
predictor = sms_knn$p_spam)
plot(sms_knn_roc, col = "red", lwd = 3, add = T)
rm(list=ls())
library(ggplot2)
install.packages("ggmap")
install.packages("ggplot2")
install.packages("raster")
install.packages("rgeos")
install.packages("maptools")
install.packages("rgdal")
library(ggmap)
library(ggplot2)
library(raster)
library(rgeos)
library(maptools)
library(rgdal)
search()
