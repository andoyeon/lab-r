str(launch)
head(launch)
# 그래프
plot(x = launch$temperature, y = launch$distress_ct)
# 상관관계 함수: cor
cor(x = launch$temperature, y = launch$distress_ct)
# 종속변수 - distress_ct
# 단순 선형 회귀
plot(launch$temperature, launch$distress_ct)
lm <- lm(formula = distress_ct ~ temperature, data = launch)
lm
summary(lm)
# a, b
a <- lm$coefficients[1]
b <- lm$coefficients[2]
# plot 그래프
abline(a = a, b = b)
# plot 그래프
abline(a = a, b = b, col = "blue")
# 다중 선형 회귀
str(launch)
lm_launch <- lm(formula = distress_ct ~ ., data = launch)
summary(lm_launch)
rm(list = ls())
insurance <- read.csv(file = "mlwr/insurance.csv")
# 데이터 확인
str(insurance)
rm(list = ls())
rm(list = ls()
rm(list = ls())
# 미국 의료 데이터
insurance <- read.csv(file = "mlwr/insurance.csv")
# 데이터 확인
str(insurance)
summary(insurance)
head(insurance)
# 종속 변수 - expenses
boxplot(insurance$expenses)
hist(insurance$expenses)
# 종속 변수 - expenses
boxplot(insurance$expenses)
# 상관계수: cor(x, y)
cor(insurance$age, insurance$expenses)
# 상관계수: cor(x, y)
cor(insurance$bmi, insurance$expenses)
library("psych")
pairs.panels(insurance)
pairs.panels(insurance)
rm(list = ls())
# 1. 데이터 준비
wine <- read.csv(file = "mlwr/whitewines.csv")
# 2. 데이터 확인, 전처리
str(wine)
# 4,898 obs.(예시), 1 variables(특징) - white wine 데이터
summary(wine)
# 종속 변수(quality)의 분포
hist(wine$quality)
# 미국 의료 데이터
insurance <- read.csv(file = "mlwr/insurance.csv")
# 데이터 확인
str(insurance)
summary(insurance)
head(insurance)
# 종속 변수 - expenses
boxplot(insurance$expenses)
hist(insurance$expenses)
# 상관계수: cor(x, y)
cor(insurance$bmi, insurance$expenses)
pairs.panels(insurance)
# 다중 선형 회귀
lm <- lm(formula = expenses ~ ., data = insurance)
summary(lm)
# regression tree를 사용하기 위한 패키지
# rpart: recursive partioning
install.packages("rpart")
library(rpart)
# 3. 모델 학습
# 학습 데이터 세트(75%)/테스트 데이터 세트(25%)
4898 * 0.75
wine_train <- wine[1:3574, ]
wine_train <- wine[1:3674, ]
wine_test <- wine[3675:4898, ]
# 3. 모델 학습
# 학습 데이터 세트(75%)/테스트 데이터 세트(25%)
head(wine)
# 학습 데이터를 rpart 패키지를 사용해서 학습시킴
wine_rpart <- rpart(formula = quality ~ ., data = wine_train)
wine_rpart
summary(wine_rpart)
# rpart(회귀 트리) 결과를 시각적으로 보여주는 패키지
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(x = wine_rpart, digits = 3)
rpart.plot(wine_rpart, digits = 4, fallen.leaves = T, extra = 101)
rpart.plot(wine_rpart, digits = 4, fallen.leaves = T)
rpart.plot(wine_rpart, digits = 4, fallen.leaves = T)
rpart.plot(x = wine_rpart, digits = 3)
rpart.plot(wine_rpart, digits = 4, fallen.leaves = T)
rpart.plot(wine_rpart, digits = 4, fallen.leaves = F)
# 4. 모델 평가 - regression tree가 테스트 데이터를 얼마나 잘 설명?
wine_predict <- predict(wine_rpart, wine_test)
summary(wine_predict)
summary(wine_test$quality)
# 상관 계수(correlation coefficient):
cor(wine_predict, wine_test$quality)
head(wine_predict)
tail(wine_predict)
return(mean(abs(actual - predict)))
# 모델 성능 평가 2)
# MAE(Mean Absolute Error): 평균 절대 오차
# 오차(실제값 - 예측값)들의 절대값의 평균
MAE <- function(actual, predict) {
return(mean(abs(actual - predict)))
}
# 함수 테스트
MAE(actual = c(1, 2, 3), predict = c(1.1, 1.9, 3.0))
MAE(actual = wine_test$quality, predict = wine_predict)
summary(lm)
# 변수 추가
insurance$age2 <- insurance$age ^ 2
head(insurance(c("age", "age2")))
head(insurance[(]c("age", "age2")])
head(insurance[(c("age", "age2")])
head(insurance[c("age", "age2")])
insurance$bmi30 <- ifelse(insurance$bmi >= 30, 1, 0)
head(insurance[c("bmi", "bmi30")])
str(insurance)
ins_model2 <- lm(formula = expenses ~ age + sex + bmi + children + smokrer +
region + expenses + age2 + bmi30 + smoker*bmi30)
ins_model2 <- lm(formula = expenses ~ age + sex + bmi + children + smoker +
region + expenses + age2 + bmi30 + smoker*bmi30)
ins_model2 <- lm(formula = expenses ~ age + sex + bmi + children + smoker +
region + age2 + bmi30 + smoker*bmi30)
ins_model2 <- lm(formula = expenses ~ age + sex + bmi + children + smoker +
region + age2 + bmi30 + smoker*bmi30,
data = insureance)
ins_model2 <- lm(formula = expenses ~ age + sex + bmi + children + smoker +
region + age2 + bmi30 + smoker*bmi30,
data = insurance)
summary(ins_model2)
# 5. 모델 성능 향상
# 모델 트리(Model Tree):
# Regression Tree(분류) + Regression Modeling(회귀 모델 적용)
# 교재: RWeka 패키지의 M5P 함수 사용
# Cubist 패키지: 규칙 학습 기반 분류 + M5P알고리즘 회귀 모델 적용
install.packages("Cubist")
library(Cubist)
# cubist(x = 훈련데이터, y = 훈련 데이터의 결과)
wine_cubist <- cubist(x = wine_train[-12], y = wine_train$quality)
wine_cubist
summary(wine_cubist)
# 모델 트리의 성능 테스트
wine_predict2 <- predict(wine_cubist, wine_test)
head(wine_predict2)
summary(wine_predict2)
summary(wine_test$quality)
# 상관 계수
cor(wine_predict2, wine_test$quality)
# MAE: 평균 절대 오차
MAE)(wine_cubist, wine_test$quality)
# MAE: 평균 절대 오차
MAE(wine_cubist, wine_test$quality)
# MAE: 평균 절대 오차
MAE(wine_predict2, wine_test$quality)
rm(list = ls())
# 레드와인 데이터 준비
wine <- read.csv(file = "mlwr/redwines.csv")
# 데이터 확인
str(wine)
head(wine)
# 학습데이터세트(75%), 테스트데이터세트(25%)
1599 * 0.75
wine_train <- wine[1:1200, ]
wine_test <- wine[1201:1599, ]
# 학습 데이터를 rpart패키지를 이용하여 학습시키기
wine_rpart <- rpart(formula = quality ~ ., data = wine_train)
wine_rpart
summary(wine_rpart)
# 회귀 트리
rpart.plot(x = wine_rpart, digits = 3)
# 모델 평가 - regression tree가 테스트 데이터를 얼마나 잘 설명하는가?
wine_predict <- predict(wine_rpart, wine_test)
head(wine_predict)
tail(wine_predict)
summary(wine_predict)
summary(wine_test$quality)
# 모델 성능 평가
# 1) 상관 계수
cor(wine_predict, wine_test$quality)
# 2) MAE
MAE <- function(actual, predict) {
return(mean(abs(actual - predict)))
}
MAE(actual = wine_test$quality, predict = wine_predict)
# 모델 성능 향상
# 모델 트리: cubist
wine_cubist <- cubist(x = wine_train[-12], y = wine_train$quality)
summary(wine_cubist)
# 모델 트리 성능 테스트
wine_predict2 <- predict(wine_cubist, wine_test)
head(wine_predict2)
summary(wine_predict2)
summary(wine_test$quality)
# 상관 계수
cor(wine_predict2, wine_test$quality)
# MAE
MAE(actual = wine_test$quality, predict = wine_cubist)
# MAE
MAE(actual = wine_test$quality, wine_predict2)
# 모델 트리 성능 테스트
wine_predict2 <- predict(wine_cubist, wine_test)
# 상관 계수
cor(wine_predict2, wine_test$quality)   # 0.668
# 회귀 트리
rpart.plot(x = wine_rpart, digits = 3, cex = 2)
# 회귀 트리
rpart.plot(x = wine_rpart, digits = 3, cex = 0.5)
# 회귀 트리
rpart.plot(x = wine_rpart, digits = 3, cex = 1)
# 회귀 트리
rpart.plot(x = wine_rpart, digits = 3, cex = 0.7)
rm(list = ls())
# Artificial Neural Network(인공 신경망)
# f(x) = 2x + 1
curve(expr = 2 * x + 1, from = -5, to = 5)
# sigmoid 함수: f(x) = 1 / [1 + exp(-x)]
curve(expr = 1 / (1 + exp(-x)), from = -10, to = 10)
# hypobolic tangent: f(x) = tanh(x)
curve(expr = tanh(x), from = -5, to = 5)
# 콘크리트의 강도 예측
# 1. 데이터 준비
concrete <- read.csv(file = "mlwr/concrete.csv")
# 2. 데이터 확인, 전처리
str(concrete)
summary(concrete)
normalization <- function(x) {
return((x - min()) / (max(x) - min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalization))
normalization <- function(x) {
return((x - min()) / (max(x) - min(x)))
}
concrete_norm <- as.data.frame(lapply(conrete, normalization))
concrete_norm <- as.data.frame(lapply(concrete, normalization))
# 2. 데이터 확인, 전처리
str(concrete)
summary(concrete)
normalization <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalization))
# 신경망 알고리즘 적용하기 위한 패키지: neuralnet
install.packages("neuralnet")
library(neuralnet)
# 3. 모델 생성, 학습
# 학습 데이터 세트(75%)/테스트 데이터 세트(25%)
1030 * 0.75
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
summary(concrete_train$strength)
summary(concrete_test$strength)
# 신경망 모델 생성
set.seed(123)
# 신경망 모델 생성
set.seed(12345)
concrete_model <- neuralnet(formula = strength ~ .,
data = concrete_train)
# 생성된 NN을 확인
plot(concrete_model)
# 4. 만들어진 NN을 평가 - 테스트 데이터 세트에 적용
model_result <- compute(concrete_model, concrete_test[-9])
head(model_result)
summary(model_result)
# 생성된 NN을 확인
plot(concrete_model)
predict_result <- model_result$net.result
# 예측 결과와 실제 값의 상관 관계 = 상관 계수
cor(predict_result, concrete_test$strength)
concrete_test[255:257, 9]
# 5. 모델 향상
model2 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = 2)
plot(model2)
model5 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = 5)
plot(model5)
# 각 모델(model2, model5)에서 예측 결과와 실제 strength간의 상관 계수를 계산
# 노드가 하나일 때 : 0.8
lm_model2 <- lm(formula = strength ~ ., data = concrete_train)
lm_model2
summary(lm_model2)
# 각 모델(model2, model5)에서 예측 결과와 실제 strength간의 상관 계수를 계산
# 노드가 하나일 때 : 0.8
rm(lm_model2)
# 각 모델(model2, model5)에서 예측 결과와 실제 strength간의 상관 계수를 계산
# 노드가 하나일 때 : 0.8
model2_result <- compute(model2, concrete_test[-9])
head(model2_result)
summary(model2_result)
predict2 <- model2_result$net.result
cor(predict2, concrete_test$strength)
model5_result <- compute(model5, concrete_test[-9])
head(model5_result)
summary(model5_result)
predict5 <- model5_result$net.result
cor(predict5, concrete_test$strength)
# 평균 절대 오차(MAE: Mean Absolute Error) 함수 작성
# -> 각 모델의 MAE를 계산
MAE <- function(actual, predict) {
return(mean(abs(actual - predict)))
}
MAE(actual = concrete_test$strength, predict = predict2)
MAE(actual = concrete_test$strength, predict = predict5)
# 역정규화: (정규화 ->  실제값) 함수 작성
# -> 실제 데이터 프레임(concrete)의 값들과 비교
# normalization = (x - min) / (max - min)
# x = normalization * (max - min) + min
denormalization <- function(x) {
return(normalization * (max(x) - min(x)) + min(x))
}
summary(concrete_model)
concrete_denorm <- as.data.frame(lapply(concrete_model, denormalization))
concrete_denorm <- as.data.frame(lapply(model_result, denormalization))
str(concrete)
concrete_denorm <- as.data.frame(lapply(concretet, denormalization))
concrete_denorm <- as.data.frame(lapply(concretet_norm, denormalization))
concrete_denorm <- as.data.frame(lapply(concrete, denormalization))
concrete_denorm <- as.data.frame(lapply(concrete_norm, denormalization))
concrete_denorm <- as.data.frame(lapply(concrete_model, denormalization))
concrete_denorm <- as.data.frame(lapply(model_result, denormalization))
concrete_denorm <- as.data.frame(lapply(predict_result, denormalization))
return(x * (max(x) - min(x)) + min(x))
concrete_denorm <- as.data.frame(lapply(concrete_norm, denormalization))
# 역정규화: (정규화 ->  실제값) 함수 작성
# -> 실제 데이터 프레임(concrete)의 값들과 비교
# normalization = (x - min) / (max - min)
# x = normalization * (max - min) + min
denormalization <- function(x) {
return(normalization() * (max(x) - min(x)) + min(x))
}
concrete_denorm <- as.data.frame(lapply(concrete_norm, denormalization))
# 역정규화: (정규화 ->  실제값) 함수 작성
# -> 실제 데이터 프레임(concrete)의 값들과 비교
# normalization = (x - min) / (max - min)
# x = normalization * (max - min) + min
denormalization <- function(x) {
return(normalization(x) * (max(x) - min(x)) + min(x))
}
concrete_denorm <- as.data.frame(lapply(concrete_norm, denormalization))
summary(concrete_norm)
str(concrete_norm)
summary(concrete_norm)
summary(concrete_norm)
# 역정규화: (정규화 ->  실제값) 함수 작성
# -> 실제 데이터 프레임(concrete)의 값들과 비교
# normalization = (x - min) / (max - min)
# x = normalization * (max - min) + min
denormalization <- function(x) {
max_str <- max(concrete$strength)
min_str <- min(concrete$strength)
return(normalization * (max_str - min_str) + min_str)
}
concrete_denorm <- as.data.frame(lapply(concrete_norm, denormalization))
# 역정규화: (정규화 ->  실제값) 함수 작성
# -> 실제 데이터 프레임(concrete)의 값들과 비교
# normalization = (x - min) / (max - min)
# x = normalization * (max - min) + min
denormalization <- function(x) {
max_str <- max(concrete$strength)
min_str <- min(concrete$strength)
return(x * (max_str - min_str) + min_str)
}
concrete_denorm <- as.data.frame(lapply(concrete_norm, denormalization))
summary(concrete_norm)
summary(concrete)
summary(concrete_denorm)
head(concrete)
head(concrete_denorm)
summary(concrete_denorm$strength)
summary(concrete$strength)
head(concrete$strength)
head(concrete_denorm$strength)
rm(list = ls())
concrete <- read.csv(file = "mlwr/concrete.csv")
# 데이터 확인
str(concrete)
summary(concrete)
# 정규화
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalize))
# 신경망 모델 생성, 학습
# 1) 학습 데이터 세트(75%), 테스트 데이터 세트(25%)
1030 * 0.75
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:103, ]
concrete_test <- concrete_norm[774:1030, ]
summary(concrete_train)
summary(concrete_test)
summary(concrete_train)
summary(concrete_test)
# 신경망 모델 생성: neuralnet
concrete_model <- neuralnet(formula = strength ~., data = concrete_train)
# 생성된 NN 확인: plot
plot(concrete_model)
# 만들어진 NN 평가 -  테스트 데이터 세트에 적용: compute
model_result <- compute(concrete_model, concrete_norm[-9])
# 만들어진 NN 평가 -  테스트 데이터 세트에 적용: compute
concrete_result <- compute(concrete_model, concrete_test[-9])
head(concrete_result)
summary(concrete_result)
predict_result <- concrete_result$net.result
# 예측결과와 실제 값의 상관 관계 = 상관 계수
cor(prect_result, concrete_test$strength)
# 예측결과와 실제 값의 상관 관계 = 상관 계수
cor(predict_result, concrete_test$strength)
concrete_test[255:257, 9]
# 모델 향상
concrete_model5 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = 5)
plot(concrete_model5)
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(3,2))
plot(concrete_model3)
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(3,2),
act.fct = "logical")
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(3,2),
act.fct = "logistic")
plot(concrete_model3)
plot(concrete_model3)
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(3,2),
act.fct = "tanh")
plot(concrete_model3)
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(3,2),
act.fct = "tanh")
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(3,2),
act.fct = "tanh",
col = "blue")
plot(concrete_model3)
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(3,2),
act.fct = "tanh",
col = "darkblue")
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(3,2),
act.fct = "logistic")
plot(concrete_model3, col = "red")
plot(concrete_model3, color = "red")
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(3,2),
act.fct = "logistic")
plot(concrete_model3)
# 신경망 모델 평가
model3_result <- compute(concrete_model3, concrete_test[-9])
model3_predict <- model3_result$net.result
cor(model3_predict, concrete_test$strength)
# 평균 절대 오차(MAE: Mean Absolute Error) 함수 작성
# -> 각 모델의 MAE를 계산
MAE <- function(actual, predict) {
return(mean(abs(actual - predict)))
}
MAE(actual = conctrete_test$strength, predict = model3_predict)
MAE(actual = concrete_test$strength, predict = model3_predict)
plot(concrete_model3)
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(5,2),
act.fct = "logistic")
plot(concrete_model3)
# 신경망 모델 평가
model3_result <- compute(concrete_model3, concrete_test[-9])
model3_predict <- model3_result$net.result
cor(model3_predict, concrete_test$strength)   # 0.921
# 다른 신경망 모델
concrete_model3 <- neuralnet(formula = strength ~ .,
data = concrete_train,
hidden = c(6,3),
act.fct = "logistic")
plot(concrete_model3)
# 신경망 모델 평가
model3_result <- compute(concrete_model3, concrete_test[-9])
model3_predict <- model3_result$net.result
cor(model3_predict, concrete_test$strength)   # 0.921
MAE(actual = concrete_test$strength, predict = model3_predict)  # 0.06
